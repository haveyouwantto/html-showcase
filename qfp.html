<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>QFP 音频压缩实验</title>
    <style>
        body {
            background-color: #121212;
            /* Dark background */
            color: #ffffff;
            /* White text */
            font-family: Arial, sans-serif;
            margin: auto;
            padding: 20px;
            display: flex;
            flex-direction: column;
            align-items: center;
            width: 50%;
        }

        h1 {
            margin-bottom: 20px;
        }

        #fileInput {
            margin-bottom: 20px;
        }

        canvas {
            width: 100%;
            height: 150px;
            background-color: #1e1e1e;
            /* Dark canvas */
            border: 1px solid #333;
            margin-top: 16px;
        }

        button {
            background-color: #6200ea;
            /* Purple button */
            color: white;
            border: none;
            padding: 10px 20px;
            cursor: pointer;
            border-radius: 5px;
            transition: background-color 0.3s;
            margin-left: 8px;
        }

        button:hover {
            background-color: #3700b3;
            /* Darker purple on hover */
        }

        .btn {
            display: flex;
        }

        .gray {
            color: gray;
            font-size: smaller;
            width: 50%;
        }


        @media only screen and (max-width:600px) {
            body {
                width: 100%;
            }
            .gray {
                width: 100%;
            }
        }
    </style>
</head>

<body>
    <h1>QFP 音频压缩实验</h1>
    <input type="file" id="fileInput" accept=".qfp" />
    <div class="btn">
        <button id="pause">暂停</button>
    </div>
    <canvas id="visualizer"></canvas>

    <div class="gray">
        <p>最近我突发奇想想做一个音频压缩算法。起初，我尝试将采样精度压缩到8位，但发现这样直接降低采样精度会带来明显的量化噪声。于是，我考虑保存音频的频域数据，做法是将音频转换为FFT频域表示，并将相位和幅值分别量化到8位，幅值还经过了对数处理。这样处理后，效果确实比直接在时域中压缩到8位好很多，文件大小也从原来的wav文件的38MB减半到19MB，符合预期结果。
        </p>

        <p>但相位数据的处理较为复杂。因此，我在网上搜索了一下，找了一种叫DCT的算法，便将处理流程从FFT转为DCT，结果效果差别不大，文件大小仍保持在原来的一半。于是，我开始尝试去除部分不重要的DCT系数，我设置了一个阈值，将低于此阈值的系数设为0。通过调整不同的阈值，我找到了一个在音质和压缩率之间相对平衡的数值。然而，文件大小仍没有减少，因为这些零值依然占用相同的存储空间。
        </p>

        <p>于是，我打开文件用十六进制编辑器查看，发现这些零值呈连续分布。所以，我决定采用游程编码来压缩零值序列，最后再套一层gzip以进一步压缩。效果非常显著，文件大小再次减半至9MB。之后，我注意到中频部分的音频信息被过度丢弃，因此我建立了一个表格，对不同频段设置不同的阈值，以尽量保留人耳更敏感的频段信息，这样文件最终压缩到7MB。
        </p>

        <p>最后，我想到了之前玩FM立体声发射时的思路：FM立体声通过L+R和L-R信号传输，L-R信号含有的信息相对较少。因此，我改为分别处理L+R和L-R信号，并对L-R信号设置更高的阈值。最终，文件大小压缩到6MB。到此，我发现自己无意中发现了音频压缩的经典思想。
        </p>
    </div>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/pako/1.0.11/pako.min.js"></script>
    <script>

        const visualizerCanvas = document.getElementById('visualizer');
        visualizerCanvas.width = visualizerCanvas.clientWidth;
        visualizerCanvas.height = visualizerCanvas.clientHeight;
        const visualizerCtx = visualizerCanvas.getContext('2d');

        let dataArray, analyser;

        function drawFFT() {
            visualizerCtx.clearRect(0, 0, visualizerCanvas.width, visualizerCanvas.height); // Clear canvas

            if (analyser && dataArray) {
                analyser.getByteFrequencyData(dataArray); // Get frequency data
                const bufferLength = analyser.frequencyBinCount;

                const barWidth = (visualizerCanvas.width / bufferLength) + 1; // Width of each bar
                let barHeight;

                for (let i = 0; i < bufferLength; i++) {
                    barHeight = dataArray[i] / 255 * visualizerCanvas.height; // Get amplitude value
                    const offset = (visualizerCanvas.height - barHeight) / 2; // Center the bar

                    visualizerCtx.fillStyle = `hsl(${(i / bufferLength) * 360}, 100%, 50%)`; // Color gradient
                    visualizerCtx.fillRect(i * barWidth, offset, barWidth, barHeight);
                }
            }
            requestAnimationFrame(drawFFT); // Loop the draw function
        }
        requestAnimationFrame(drawFFT)

        // Function to perform a mini Fast Fourier Transform (FFT)
        function miniFFT(re, im) {
            var N = re.length;
            for (var i = 0; i < N; i++) {
                for (var j = 0, h = i, k = N; k >>= 1; h >>= 1)
                    j = (j << 1) | (h & 1);
                if (j > i) {
                    re[j] = [re[i], re[i] = re[j]][0]
                    im[j] = [im[i], im[i] = im[j]][0]
                }
            }
            for (var hN = 1; hN * 2 <= N; hN *= 2)
                for (var i = 0; i < N; i += hN * 2)
                    for (var j = i; j < i + hN; j++) {
                        var cos = Math.cos(Math.PI * (j - i) / hN),
                            sin = Math.sin(Math.PI * (j - i) / hN)
                        var tre = re[j + hN] * cos + im[j + hN] * sin,
                            tim = -re[j + hN] * sin + im[j + hN] * cos;
                        re[j + hN] = re[j] - tre; im[j + hN] = im[j] - tim;
                        re[j] += tre; im[j] += tim;
                    }
        }

        // Function to perform the inverse discrete cosine transform (IDCT)
        function miniIDCT(s) {
            var N = s.length,
                K = Math.PI / (2 * N),
                im = new Float64Array(N),
                re = new Float64Array(N);
            re[0] = s[0] / N / 2;
            for (var i = 1; i < N; i++) {
                var im2 = Math.sin(i * K), re2 = Math.cos(i * K);
                re[i] = (s[N - i] * im2 + s[i] * re2) / N / 2;
                im[i] = (im2 * s[i] - s[N - i] * re2) / N / 2;
            }
            miniFFT(im, re)
            const mul = s.length;
            for (var i = 0; i < N / 2; i++) {
                s[2 * i] = re[i] * mul;
                s[2 * i + 1] = re[N - i - 1] * mul;
            }
        }

        // Function to decompress run-length encoded data
        function rleDecompress(data) {
            const decompressed = []; // Array to hold decompressed data
            let i = 0;

            while (i < data.length) {
                const byte = data[i];

                if (byte === -128) {
                    i += 1;
                    let zeroCount = 0;

                    // Count the number of zeros
                    while (i < data.length && (data[i] & 0xFF) === 0xFF) {
                        zeroCount += 0xFF;
                        i += 1;
                    }

                    if (i < data.length) {
                        zeroCount += (data[i] & 0xFF) + 1;
                        i += 1;
                    }

                    // Push zeros to the decompressed array
                    decompressed.push(...Array(zeroCount + 2).fill(0));
                } else {
                    decompressed.push(byte); // Add byte to decompressed array
                    i += 1;
                }
            }

            return new Int8Array(decompressed); // Return as Int8Array
        }

        // Function to pad an array to a target length
        function padArray(arr, targetLength) {
            const paddedArray = new Int8Array(targetLength); // Create a new Int8Array

            // Copy the original array into the new array
            const lengthToCopy = Math.min(arr.length, targetLength);
            paddedArray.set(arr.subarray(0, lengthToCopy));

            return paddedArray; // Return padded array
        }

        // Function to dequantize amplitudes
        function dequantizeAmp(ampQ) {
            const amp = new Float32Array(ampQ.length); // Create a Float32Array

            for (let i = 0; i < ampQ.length; i++) {
                // Dequantize the amplitudes
                const amplitude = Math.pow(10, (Math.abs(ampQ[i]) - 127) / 20);
                amp[i] = ampQ[i] < 0 ? -amplitude : amplitude; // Store signed amplitude
            }

            return amp; // Return dequantized amplitudes
        }

        // Class to decode QFP files
        class QFPDecoder {
            constructor(arrayBuffer) {
                // Decompress the gzipped data
                const decompressedData = pako.inflate(new Uint8Array(arrayBuffer));

                this.buffer = decompressedData.buffer; // Use the decompressed data
                this.view = new DataView(this.buffer);
                this.ptr = 0;
                this.readHeader();
            }

            readHeader() {
                let magic = new TextDecoder('utf-8').decode(this.buffer.slice(0, 4)); // Read magic number
                console.log("magic: " + magic);
                if (magic !== 'QFPA') throw new Error("magic not match"); // Check magic number

                this.ptr += 4; // Move pointer

                // Read version, sample rate, and window size
                this.version = this.view.getUint8(this.ptr++, true);
                this.sampleRate = this.view.getUint32(this.ptr, true);
                this.ptr += 4;
                this.winSize = this.view.getUint32(this.ptr, true);
                this.ptr += 4;

                console.log("version: " + this.version);
                console.log("sample rate: " + this.sampleRate);
                console.log("win size:" + this.winSize);
            }

            readFrame() {
                const lr = []; // Array to hold left and right channel data
                for (let ch = 0; ch < 2; ch++) {
                    const length = this.view.getInt16(this.ptr, true); // Read length of the frame
                    this.ptr += 2; // Move pointer

                    let ampQ = new Int8Array(this.buffer.slice(this.ptr, this.ptr + length)); // Read amplitude data
                    this.ptr += length; // Move pointer

                    ampQ = rleDecompress(ampQ); // Decompress amplitude data
                    ampQ = padArray(ampQ, this.winSize); // Pad the array

                    let amp = dequantizeAmp(ampQ).map(e => e * this.winSize); // Dequantize amplitudes

                    miniIDCT(amp); // Apply IDCT

                    lr[ch] = amp; // Store channel data
                }

                const l = new Float32Array(this.winSize), r = new Float32Array(this.winSize); // Create arrays for left and right channels

                // Calculate left and right channels
                for (let i = 0; i < this.winSize; i++) {
                    l[i] = (lr[0][i] + lr[1][i]) / 64; // Left channel
                    r[i] = (lr[0][i] - lr[1][i]) / 64; // Right channel
                }

                return [l, r]; // Return left and right channels
            }
        }

        let scriptProcessor;
        let paused = false;

        document.getElementById('fileInput').addEventListener('change', e => {
            const fileInput = document.getElementById('fileInput');
            const file = fileInput.files[0];

            if (!file) {
                alert('Please select a file.'); // Alert if no file is selected
                return;
            }

            const reader = new FileReader(); // Create a FileReader

            // Read the file as an ArrayBuffer
            reader.readAsArrayBuffer(file);

            reader.onload = function (event) {
                try {
                    const arrayBuffer = event.target.result; // Get the result from the reader

                    let qfp = new QFPDecoder(arrayBuffer); // Create a new QFPDecoder

                    const ctx = new AudioContext({ sampleRate: qfp.sampleRate, latencyHint: "playback" });

                    analyser = ctx.createAnalyser();
                    analyser.fftSize = 2048; // Size of the FFT

                    const bufferLength = analyser.frequencyBinCount;
                    dataArray = new Uint8Array(bufferLength);

                    // Create ScriptProcessorNode
                    if (scriptProcessor) {
                        scriptProcessor.disconnect();
                    }

                    const bufferSize = qfp.winSize; // Set buffer size
                    scriptProcessor = ctx.createScriptProcessor(bufferSize, 2, 2); // 2 input channels, 2 output channels

                    // On audio process event
                    scriptProcessor.onaudioprocess = function (audioProcessingEvent) {
                        if (!paused) {
                            const outputData = audioProcessingEvent.outputBuffer; // Get output buffer

                            // Read frame data for both left and right channels
                            const [l, r] = qfp.readFrame();

                            // Copy left and right channel data into the output buffer
                            const leftChannel = outputData.getChannelData(0); // Left channel
                            const rightChannel = outputData.getChannelData(1); // Right channel

                            for (let i = 0; i < bufferSize; i++) {
                                leftChannel[i] = i < l.length ? l[i] : 0; // Fill left channel
                                rightChannel[i] = i < r.length ? r[i] : 0; // Fill right channel
                            }
                        }
                    };

                    // Connect the script processor to the audio context's destination
                    scriptProcessor.connect(analyser);
                    analyser.connect(ctx.destination);

                    // Start the audio processing
                    if (paused) pauseBtn.click();// Resume audio if paused

                    ctx.resume().then(() => {
                        console.log('Audio context resumed, processing frames...');
                    });
                } catch (error) {
                    alert("Error decoding QFP:", error);
                }
            };

            reader.onerror = function (event) {
                console.error('Error reading file:', event); // Log error
                alert('Error reading file.'); // Alert on error
            };
        })

        let pauseBtn = document.getElementById('pause');   // Pause button
        pauseBtn.addEventListener('click', function () {
            paused = !paused;  // Toggle pause state

            if (paused) {
                pauseBtn.innerHTML = '播放';  // Set pause button text to Play
            } else {
                pauseBtn.innerHTML = '暂停';    // Set pause button text to Pause
            }
        });
    </script>
</body>

</html>