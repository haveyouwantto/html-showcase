<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>QFP 音频压缩实验</title>
    <style>
        body {
            background-color: #121212;
            /* Dark background */
            color: #ffffff;
            /* White text */
            font-family: Arial, sans-serif;
            margin: auto;
            width: 50%;
        }

        .container {
            display: flex;
            flex-direction: column;
            align-items: center;
        }

        .status {
            display: flex;
            align-items: center;
            margin-top: 16px;
            width: 100%;
            justify-content: center;
        }

        #progress {
            height: 10px;
            width: 100%;
            background-color: #333;
            margin-right: 16px;
        }

        #progress-inner {
            background-color: #8e4bec;
            width: 0;
            height: 100%;
        }

        #time {
            min-width: fit-content;
        }

        h1 {
            margin-bottom: 20px;
        }

        #fileInput {
            margin-bottom: 20px;
        }

        canvas {
            width: 100%;
            height: 150px;
            background-color: #1e1e1e;
            /* Dark canvas */
            border: 1px solid #333;
            margin-top: 16px;
        }

        button {
            background-color: #8e4bec;
            /* Purple button */
            color: white;
            border: none;
            padding: 10px 20px;
            cursor: pointer;
            border-radius: 5px;
            transition: background-color 0.3s;
            margin-left: 8px;
        }

        button:hover {
            background-color: #6400ea;
            /* Darker purple on hover */
        }

        .btn {
            display: flex;
        }

        .gray {
            color: gray;
            font-size: smaller;
            width: 50%;
        }


        @media only screen and (max-width:600px) {
            body {
                width: 95%;
            }

            .gray {
                width: 100%;
            }
        }
    </style>
</head>

<body>
    <div class="container">
        <h1>QFP 音频压缩实验</h1>
        <input type="file" id="fileInput" accept=".qfp" />
        <div class="btn">
            <button id="pause">播放</button>
            <button id="replay">重播</button>
        </div>
        <div class="status">
            <div id="progress">
                <div id="progress-inner"></div>
            </div>
            <div id="time">00:00 / 00:00</div>
        </div>
        <canvas id="visualizer"></canvas>

        <div class="gray">
            <p>最近我突发奇想想做一个音频压缩算法。起初，我尝试将采样精度压缩到8位，但发现这样直接降低采样精度会带来明显的量化噪声。于是，我考虑保存音频的频域数据，做法是将音频转换为FFT频域表示，并将相位和幅值分别量化到8位，幅值还经过了对数处理。这样处理后，效果确实比直接在时域中压缩到8位好很多，文件大小也从原来的wav文件的38MB减半到19MB，符合预期结果。
            </p>

            <p>但相位数据的处理较为复杂。因此，我在网上搜索了一下，找了一种叫DCT的算法，便将处理流程从FFT转为DCT，结果效果差别不大，文件大小仍保持在原来的一半。于是，我开始尝试去除部分不重要的DCT系数，我设置了一个阈值，将低于此阈值的系数设为0。通过调整不同的阈值，我找到了一个在音质和压缩率之间相对平衡的数值。然而，文件大小仍没有减少，因为这些零值依然占用相同的存储空间。
            </p>

            <p>于是，我打开文件用十六进制编辑器查看，发现这些零值呈连续分布。所以，我决定采用游程编码来压缩零值序列，最后再套一层gzip以进一步压缩。效果非常显著，文件大小再次减半至9MB。之后，我注意到中频部分的音频信息被过度丢弃，因此我建立了一个表格，对不同频段设置不同的阈值，以尽量保留人耳更敏感的频段信息，这样文件最终压缩到7MB。
            </p>

            <p>最后，我想到了之前玩FM立体声发射时的思路：FM立体声通过L+R和L-R信号传输，L-R信号含有的信息相对较少。因此，我改为分别处理L+R和L-R信号，并对L-R信号设置更高的阈值。最终，文件大小压缩到6MB。到此，我发现自己无意中发现了音频压缩的经典思想。
            </p>
        </div>
    </div>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/pako/1.0.11/pako.min.js"></script>
    <script>

        const visualizerCanvas = document.getElementById('visualizer');
        visualizerCanvas.width = visualizerCanvas.clientWidth;
        visualizerCanvas.height = visualizerCanvas.clientHeight;
        const visualizerCtx = visualizerCanvas.getContext('2d');

        const ctx = new AudioContext({ latencyHint: "playback" });

        const analyser = ctx.createAnalyser();
        analyser.fftSize = 2048; // Size of the FFT

        const bufferLength = analyser.frequencyBinCount;
        const dataArray = new Uint8Array(bufferLength);

        const timeDisplay = document.getElementById("time")
        const progressDisplay = document.getElementById("progress-inner")

        function padding(num) {
            if (isNaN(num) || !isFinite(num)) {
                return '**';
            }
            if (num < 10) {
                return '0' + num;
            }
            else {
                return num;
            }
        }

        function formatTime(seconds) {
            if (isNaN(seconds) || !isFinite(seconds)) return "**:**";

            let sec = parseInt(seconds % 60);
            let minutes = seconds / 60;
            let min = parseInt(minutes % 60);
            if (minutes < 60) {
                return padding(min) + ':' + padding(sec);
            } else {
                let hours = minutes / 60;
                return padding(parseInt(hours)) + ':' + padding(min) + ':' + padding(sec);
            }
        }

        function drawFFT() {
            visualizerCtx.clearRect(0, 0, visualizerCanvas.width, visualizerCanvas.height); // Clear canvas

            if (analyser && dataArray) {
                analyser.getByteFrequencyData(dataArray); // Get frequency data
                const bufferLength = analyser.frequencyBinCount;

                const barWidth = (visualizerCanvas.width / bufferLength); // Width of each bar
                let barHeight;

                for (let i = 0; i < bufferLength; i++) {
                    barHeight = dataArray[i] / 255 * visualizerCanvas.height; // Get amplitude value
                    const offset = (visualizerCanvas.height - barHeight) / 2; // Center the bar

                    visualizerCtx.fillStyle = `hsl(${(i / bufferLength) * 360}, 100%, 50%)`; // Color gradient
                    visualizerCtx.fillRect(i * barWidth, offset, barWidth + 1, barHeight);
                }
            }
            requestAnimationFrame(drawFFT); // Loop the draw function
        }
        requestAnimationFrame(drawFFT)

        // Function to perform a mini Fast Fourier Transform (FFT)
        function miniFFT(re, im) {
            var N = re.length;
            for (var i = 0; i < N; i++) {
                for (var j = 0, h = i, k = N; k >>= 1; h >>= 1)
                    j = (j << 1) | (h & 1);
                if (j > i) {
                    re[j] = [re[i], re[i] = re[j]][0]
                    im[j] = [im[i], im[i] = im[j]][0]
                }
            }
            for (var hN = 1; hN * 2 <= N; hN *= 2)
                for (var i = 0; i < N; i += hN * 2)
                    for (var j = i; j < i + hN; j++) {
                        var cos = Math.cos(Math.PI * (j - i) / hN),
                            sin = Math.sin(Math.PI * (j - i) / hN)
                        var tre = re[j + hN] * cos + im[j + hN] * sin,
                            tim = -re[j + hN] * sin + im[j + hN] * cos;
                        re[j + hN] = re[j] - tre; im[j + hN] = im[j] - tim;
                        re[j] += tre; im[j] += tim;
                    }
        }

        // Function to perform the inverse discrete cosine transform (IDCT)
        function miniIDCT(s) {
            var N = s.length,
                K = Math.PI / (2 * N),
                im = new Float64Array(N),
                re = new Float64Array(N);
            re[0] = s[0] / N / 2;
            for (var i = 1; i < N; i++) {
                var im2 = Math.sin(i * K), re2 = Math.cos(i * K);
                re[i] = (s[N - i] * im2 + s[i] * re2) / N / 2;
                im[i] = (im2 * s[i] - s[N - i] * re2) / N / 2;
            }
            miniFFT(im, re)
            const mul = N * Math.sqrt(2 / N);
            for (var i = 0; i < N / 2; i++) {
                s[2 * i] = re[i] * mul;
                s[2 * i + 1] = re[N - i - 1] * mul;
            }
        }

        // Function to decompress run-length encoded data
        function rleDecompress(data) {
            const decompressed = []; // Array to hold decompressed data
            let i = 0;

            while (i < data.length) {
                const byte = data[i];

                if (byte === -128) {
                    i += 1;
                    let zeroCount = 0;

                    // Count the number of zeros
                    while (i < data.length && (data[i] & 0xFF) === 0xFF) {
                        zeroCount += 0xFF;
                        i += 1;
                    }

                    if (i < data.length) {
                        zeroCount += (data[i] & 0xFF) + 1;
                        i += 1;
                    }

                    // Push zeros to the decompressed array
                    decompressed.push(...Array(zeroCount + 2).fill(0));
                } else {
                    decompressed.push(byte); // Add byte to decompressed array
                    i += 1;
                }
            }

            return new Int8Array(decompressed); // Return as Int8Array
        }

        // Function to pad an array to a target length
        function padArray(arr, targetLength) {
            const paddedArray = new Int8Array(targetLength); // Create a new Int8Array

            // Copy the original array into the new array
            const lengthToCopy = Math.min(arr.length, targetLength);
            paddedArray.set(arr.subarray(0, lengthToCopy));

            return paddedArray; // Return padded array
        }

        // Function to dequantize amplitudes
        function dequantizeAmp(ampQ) {
            const amp = new Float32Array(ampQ.length); // Create a Float32Array

            for (let i = 0; i < ampQ.length; i++) {
                // Dequantize the amplitudes
                const amplitude = Math.pow(10, (Math.abs(ampQ[i]) - 127) / 20);
                amp[i] = ampQ[i] < 0 ? -amplitude : amplitude; // Store signed amplitude
            }

            return amp; // Return dequantized amplitudes
        }

        // Class to decode QFP files
        class QFPDecoder {
            constructor(arrayBuffer) {
                // Decompress the gzipped data
                const decompressedData = pako.inflate(new Uint8Array(arrayBuffer));

                this.buffer = decompressedData.buffer; // Use the decompressed data
                this.view = new DataView(this.buffer);
                this.ptr = 0;
                this.read = 0;
                this.readHeader();
            }

            readHeader() {
                let magic = new TextDecoder('utf-8').decode(this.buffer.slice(0, 4)); // Read magic number
                console.log("magic: " + magic);
                if (magic !== 'QFPA') throw new Error("magic not match"); // Check magic number

                this.ptr += 4; // Move pointer

                // Read version, sample rate, and window size
                this.version = this.view.getUint8(this.ptr++, true);
                this.sampleRate = this.view.getUint32(this.ptr, true);
                this.ptr += 4;
                this.winSize = this.view.getUint32(this.ptr, true);
                this.ptr += 4;
                this.numWindows = this.view.getUint32(this.ptr, true);
                this.ptr += 4;

                console.log("version: " + this.version);
                console.log("sample rate: " + this.sampleRate);
                console.log("win size:" + this.winSize);
                console.log("num win:" + this.numWindows);

                this.duration = this.numWindows * (this.winSize / this.sampleRate)
            }

            readFrame() {
                if (this.read >= this.numWindows) throw new Error("No more frames to read");

                const lr = []; // Array to hold left and right channel data
                for (let ch = 0; ch < 2; ch++) {
                    const length = this.view.getUint16(this.ptr, true); // Read length of the frame
                    this.ptr += 2; // Move pointer

                    let ampQ = new Int8Array(this.buffer.slice(this.ptr, this.ptr + length)); // Read amplitude data
                    this.ptr += length; // Move pointer

                    ampQ = rleDecompress(ampQ); // Decompress amplitude data
                    ampQ = padArray(ampQ, this.winSize); // Pad the array

                    let amp = dequantizeAmp(ampQ).map(e => e * this.winSize); // Dequantize amplitudes

                    miniIDCT(amp); // Apply IDCT

                    lr[ch] = amp; // Store channel data
                }

                const l = new Float32Array(this.winSize), r = new Float32Array(this.winSize); // Create arrays for left and right channels

                // Calculate left and right channels
                for (let i = 0; i < this.winSize; i++) {
                    l[i] = (lr[0][i] + lr[1][i]) / 2; // Left channel
                    r[i] = (lr[0][i] - lr[1][i]) / 2; // Right channel
                }

                this.read++;
                return [l, r]; // Return left and right channels
            }

            reset() {
                this.ptr = 0;
                this.read = 0;
                this.readHeader();
            }
        }

        class QFPPlayer {
            constructor(qfp) {
                this.qfp = qfp;
                this.t = 0;
                this.started = false;
                this.nodeList = [];
                this.stopped = false;
            }

            start() {
                if (this.started) throw new Error("QFPPlayer can only be started once.");
                this.startTime = ctx.currentTime;
                this.updateProgress();

                let preloadFrames = Math.floor(5 / (this.qfp.winSize / this.qfp.sampleRate)); // Preload 5 sec
                for (let i = 0; i < preloadFrames; i++) {
                    this.playFrame();
                }
            }

            setPaused(b) {
                if (b) {
                    ctx.suspend();
                } else {
                    ctx.resume();
                }
            }

            updateProgress() {
                let currentTime = Math.min(ctx.currentTime - this.startTime, this.qfp.duration)
                let prog = currentTime / this.qfp.duration;
                timeDisplay.textContent = `${formatTime(currentTime)} / ${formatTime(this.qfp.duration)}`
                progressDisplay.style.width = (prog * 100) + "%"
            }

            playFrame() {
                if (!this.stopped) {
                    const frame = this.qfp.readFrame();

                    const buffer = ctx.createBuffer(2, this.qfp.winSize, this.qfp.sampleRate)
                    const l = buffer.getChannelData(0)
                    const r = buffer.getChannelData(1)
                    l.set(frame[0])
                    r.set(frame[1])

                    const node = ctx.createBufferSource();
                    node.buffer = buffer;
                    node.onended = () => {
                        node.disconnect();
                        this.nodeList.shift();

                        if (!this.stopped) {
                            this.updateProgress();
                            this.playFrame();
                        }
                    };
                    node.connect(analyser).connect(ctx.destination)
                    node.start(this.startTime + this.t);
                    this.nodeList.push(node);
                    this.t += (1 / this.qfp.sampleRate * this.qfp.winSize)
                }
            }

            stop() {
                if (this.stopped) throw new Error("QFPPlayer already stopped.");
                for (const node of this.nodeList) {
                    node.disconnect();
                }
                this.stopped = true;
            }

            replay() {
                this.stop();
                this.t = 0;
                this.stopped = false;
                this.started = false;
                this.qfp.reset();
                this.start();
            }
        }

        let paused = true;
        let player;

        document.getElementById('fileInput').addEventListener('change', e => {
            const fileInput = document.getElementById('fileInput');
            const file = fileInput.files[0];

            if (!file) {
                alert('Please select a file.'); // Alert if no file is selected
                return;
            }

            const reader = new FileReader(); // Create a FileReader

            // Read the file as an ArrayBuffer
            reader.readAsArrayBuffer(file);

            reader.onload = function (event) {
                try {
                    const arrayBuffer = event.target.result; // Get the result from the reader

                    let qfp = new QFPDecoder(arrayBuffer); // Create a new QFPDecoder
                    if (player) player.stop();
                    player = new QFPPlayer(qfp);
                    player.start();

                    // Start the audio processing
                    if (paused) pauseBtn.click();// Resume audio if paused
                } catch (error) {
                    alert("Error decoding QFP:", error);
                    throw error;
                }
            };

            reader.onerror = function (event) {
                console.error('Error reading file:', event); // Log error
                alert('Error reading file.'); // Alert on error
            };
        })

        let pauseBtn = document.getElementById('pause');   // Pause button
        pauseBtn.addEventListener('click', function () {
            paused = !paused;  // Toggle pause state

            if (paused) {
                ctx.suspend();
                pauseBtn.innerHTML = '播放';  // Set pause button text to Play
            } else {
                ctx.resume();
                pauseBtn.innerHTML = '暂停';    // Set pause button text to Pause
            }
        });

        document.getElementById('replay').addEventListener('click', e => {
            player.replay();
        })
    </script>
</body>

</html>