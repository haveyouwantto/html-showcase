<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ImageTape</title>
    <style>
        /* ÈÄöÁî®ÊöóÈªëÊ®°Âºè Material Design È£éÊ†ºËÆæÁΩÆ */
        body {
            background-color: #121212;
            /* Ê∑±Ëâ≤ËÉåÊôØ */
            color: #e0e0e0;
            /* ÊµÖËâ≤ÊñáÂ≠ó */
            font-family: 'Roboto', 'Arial', sans-serif;
            margin: 0;
            padding: 0;
            line-height: 1.6;
        }

        /* Êñá‰ª∂ËæìÂÖ•Ê°ÜÂíåÊåâÈíÆ */
        input[type="file"],
        button {
            /* Teal Ê∑±Ëâ≤ */
            color: #ffffff;
            /* ÁôΩËâ≤ÊñáÂ≠ó */
            border: none;
            border-radius: 4px;
            padding: 10px 20px;
            margin: 10px 0;
            font-size: 1rem;
            cursor: pointer;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.3);
            transition: background-color 0.3s, box-shadow 0.3s;
        }

        input[type="file"] {
            background-color: #004d4040;
        }

        button {
            background-color: #00695c;
        }

        input[type="file"]::file-selector-button {
            background-color: #00695c;
            /* Êõ¥‰∫ÆÁöÑ Teal */
            color: #e0e0e0;
            border: none;
            padding: 8px 12px;
            border-radius: 4px;
            cursor: pointer;
            transition: background-color 0.3s, box-shadow 0.3s;
        }

        input[type="file"]::file-selector-button:hover,
        button:hover {
            background-color: #009c89;
            /* Hover Áä∂ÊÄÅ */
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.4);
        }

        /* Canvas Ê†∑Âºè */
        canvas {
            display: block;
            background-color: #263238;
            border: none;
            border-radius: 8px;
            width: 100%;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.3);
            cursor: pointer;
        }

        /* Ê†áÈ¢òÂíåÊèèËø∞ÊñáÂ≠ó */
        h1,
        h2,
        p {
            text-align: center;
            margin: 10px 0;
        }

        h1 {
            color: #ffffff;
            font-size: 2.2rem;
        }

        h2 {
            color: #b2dfdb;
            /* ÊµÖ Teal */
            font-size: 1.6rem;
        }

        p {
            color: #80cbc4;
            /* Êõ¥ÊµÖ Teal */
            font-size: 1rem;
        }

        /* Ë∂ÖÈìæÊé•Ê†∑Âºè */
        a {
            color: #4db6ac;
            /* Teal Ëâ≤ÈìæÊé• */
            text-decoration: none;
            transition: color 0.3s;
        }

        a:hover {
            color: #26a69a;
            /* Hover Áä∂ÊÄÅÁöÑÊõ¥‰∫Æ Teal */
        }

        /* Footer Ê†∑Âºè */
        footer {
            text-align: center;
            color: #607d8b;
            margin: 20px 0;
            font-size: 0.9rem;
        }

        /* ÂÆπÂô®Â∏ÉÂ±Ä */
        .container {
            display: flex;
            flex-direction: column;
            align-items: center;
        }


        .status {
            display: flex;
            align-items: center;
            margin-top: 8px;
            width: 95%;
            justify-content: center;
        }

        #progress {
            height: 10px;
            width: 75%;
            background-color: #333;
            margin-right: 16px;
            cursor: pointer;
            /* if clickable*/
        }

        #progress-inner {
            background-color: #008577;
            width: 0;
            height: 100%;
        }

        .canvas-container {
            position: relative;
            margin: 20px auto;
            max-width: 95%;
        }

        #time {
            min-width: fit-content;
        }

        .icon {
            font-size: 26px;
            width: 48px;
            height: 48px;
            display: inline-flex;
            align-items: center;
            justify-content: center;
        }

        #pos-marker {
            width: 100%;
            height: 2px;
            position: absolute;
            top: 0;
            left: 0;
            background-color: red;
            border-radius: 999px;
            box-shadow: 0px 0px 6px 2px red;
            transition: 0.1s;
            transition-timing-function: linear;
        }

        /* ÂìçÂ∫îÂºèË∞ÉÊï¥ */
        @media (max-width: 768px) {
            body {
                font-size: 0.9rem;
            }

            button,
            input[type="file"] {
                padding: 8px 10px;
                font-size: 0.9rem;
            }
        }
    </style>
</head>

<body>

    <h1>ImageTape</h1>

    <div class="container">
        <!-- Audio and Image Upload -->
        <div><span class="icon">üéß</span><input type="file" id="audioFile" accept="audio/*"></div>
        <div><span class="icon">üé®</span><input type="file" id="imageFile" accept="image/*"></div>

        <!-- Buttons for conversion -->
        <div>
            <button id="audioToImageBtn" class="icon">üî¥</button>
            <button id="eraseBtn" class="icon">‚ùå</button>
            <button id="pauseBtn" class="icon">‚ñ∂</button>
            <button id="downloadBtn" class="icon">üíæ</button>
        </div>
        <div class="status">
            <div id="progress">
                <div id="progress-inner"></div>
            </div>
            <div id="time">00:00 / 00:00</div>
        </div>
    </div>

    <!-- Canvas for visualizing the conversion -->
    <div class="canvas-container">
        <canvas id="canvas" width="1920" height="1080">
        </canvas>
        <div id="pos-marker"></div>
    </div>

    <script>
        let audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 8000 });
        let canvas = document.getElementById('canvas');
        let ctx = canvas.getContext('2d');
        ctx.fillStyle = "gray";
        ctx.fillRect(0, 0, canvas.width, canvas.height);

        const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);

        let audioElement = new Audio();
        let audioBuffer = null;

        let posMarker = document.getElementById('pos-marker');

        // File inputs
        let audioFileInput = document.getElementById('audioFile');
        let imageFileInput = document.getElementById('imageFile');

        // Buttons for conversion actions
        let audioToImageBtn = document.getElementById('audioToImageBtn');
        let eraseBtn = document.getElementById('eraseBtn');


        const timeDisplay = document.getElementById("time")
        const progressDisplay = document.getElementById("progress-inner")
        const progressBar = document.getElementById("progress")

        const pauseBtn = document.getElementById("pauseBtn")
        let download = document.getElementById('downloadBtn');


        function padding(num) {
            if (isNaN(num) || !isFinite(num)) {
                return '**';
            }
            if (num < 10) {
                return '0' + num;
            }
            else {
                return num;
            }
        }

        function formatTime(seconds) {
            if (isNaN(seconds) || !isFinite(seconds)) return "**:**";

            let sec = parseInt(seconds % 60);
            let minutes = seconds / 60;
            let min = parseInt(minutes % 60);
            if (minutes < 60) {
                return padding(min) + ':' + padding(sec);
            } else {
                let hours = minutes / 60;
                return padding(parseInt(hours)) + ':' + padding(min) + ':' + padding(sec);
            }
        }

        function updateProgress(currentTime, totalLength) {
            let prog = currentTime / totalLength; // Êí≠ÊîæËøõÂ∫¶ÁôæÂàÜÊØî
            timeDisplay.textContent = `${formatTime(currentTime)} / ${formatTime(totalLength)}`;
            progressDisplay.style.width = (prog * 100) + "%"; // Êõ¥Êñ∞ËøõÂ∫¶Êù°ÊòæÁ§∫
            posMarker.style.top = (prog * 100) + "%";
        }

        progressBar.addEventListener('click', e => {
            let r = e.offsetX / progressBar.offsetWidth;
            player.currentTime = player.duration * r;
        })

        class Player {
            constructor(imageData) {
                this.isPlaying = false;
                this.source = null;
                this.imageData = imageData;
                this.ptr = 0;
                this.frameSize = 1024; // Number of samples per frame
                this.sampleRate = audioContext.sampleRate;
                this.buffers = new Set();
                this.time = audioContext.currentTime;
                this.started = false;
            }

            stop() {
                for (const source of this.buffers) {
                    source.disconnect();
                    source.stop();
                }
                this.buffers.clear();
                this.pause = true;
                this.lock = null;
            }

            reset() {
                this.stop();
                this.ptr = 0; // Reset playback position
                this.started = false;
            }

            start() {
                this.time = audioContext.currentTime;
                this.pause = false;
                let lock = performance.now();
                if (!this.started) {
                    this.started = true;
                    this._playBuffer(lock);
                }
            }

            set pause(isPaused) {
                if (isPaused) {
                    audioContext.suspend();
                    this.isPlaying = false;
                } else {
                    audioContext.resume();
                    this.isPlaying = true;
                }
                updateProgress(this.currentTime, this.duration)
            }

            set currentTime(position) {
                if (!this.imageData) {
                    console.error("No image data set. Use setImageData() to set data.");
                    return;
                }

                const totalSamples = this.imageData.data.length / 4;
                const targetSample = Math.min(Math.max(0, Math.floor(position * this.sampleRate)), totalSamples);
                this.ptr = targetSample;
                updateProgress(this.currentTime, this.duration)
            }

            get currentTime() {
                return this.ptr / 8000;
            }

            get duration() {
                return this.imageData?.data?.length / 4 / 8000 ?? 0;
            }

            _playBuffer(lock) {
                if (this.lock && lock != this.lock) return;

                if (!this.lock) this.lock = lock;

                const { data } = this.imageData;
                const len = Math.min(this.frameSize, data.length / 4 - this.ptr);

                if (len <= 0) {
                    this.started = false;
                    return;
                }

                const audioData = [new Float32Array(len), new Float32Array(len)];

                // Process image data and convert to audio data
                for (let i = 0; i < len; i++, this.ptr++) {
                    // Extract RGB values from image data
                    const r = data[this.ptr * 4] / 255;
                    const g = data[this.ptr * 4 + 1] / 255;
                    const b = data[this.ptr * 4 + 2] / 255;

                    // Convert RGB to YUV
                    const y = 0.299 * r + 0.587 * g + 0.114 * b;
                    const u = -0.1687 * r - 0.3313 * g + 0.5 * b + 0.5;
                    const v = 0.5 * r - 0.419 * g - 0.0813 * b + 0.5;

                    // Normalize Y value to range [-1, 1]
                    const yQ = (y - 0.5) * 2;
                    const sign = Math.sign(yQ);

                    // Determine which channel (U or V) to use based on row index
                    const isEvenRow = parseInt(this.ptr / 1920) % 2 === 0;
                    const uvQ = isEvenRow ? (u - 0.5) * 2 : (v - 0.5) * 2;

                    // Compute sum and difference of left and right channels
                    const lrSum = yQ * yQ * sign;
                    const lrDiff = uvQ;

                    // Calculate left and right channel audio data
                    const lChannel = lrSum + lrDiff;
                    const rChannel = lrSum - lrDiff;

                    // Store audio data in output arrays
                    audioData[0][i] = lChannel;
                    audioData[1][i] = rChannel;
                }

                const buffer = audioContext.createBuffer(2, len, this.sampleRate);
                buffer.copyToChannel(audioData[0], 0);
                buffer.copyToChannel(audioData[1], 1);

                const source = audioContext.createBufferSource();
                source.buffer = buffer;
                source.connect(audioContext.destination);

                source.onended = () => {
                    source.disconnect();
                    this.buffers.delete(source);
                    updateProgress(this.currentTime, this.duration);
                    if (this.ptr >= 0 && this.ptr < data.length / 4 && this.started) {
                        this._playBuffer(lock);
                    } else {
                        this.reset();
                    }
                };
                this.buffers.add(source);

                console.log(this.time)
                source.start(this.time);
                this.time += buffer.duration;
            }

            record(audioBuffer) {
                let prevPos = this.ptr;

                // Get audio channels (left and right, or use left if mono)
                let lChannel = audioBuffer.getChannelData(0);
                let rChannel = audioBuffer.numberOfChannels >= 2 ? audioBuffer.getChannelData(1) : lChannel;

                // Prepare image data for canvas manipulation
                let data = imageData.data;

                // Temporary buffers for Y, U, and V channels
                const tempY = new Float32Array(3840);
                const tempU = new Float32Array(3840);
                const tempV = new Float32Array(3840);

                // Process audio data in chunks of 3840 samples
                for (let i = 0; i < lChannel.length; i += 3840) {
                    for (let j = 0; j < 3840; j++) {
                        const idx = i + j;

                        // Ensure the index is within bounds
                        if (idx >= lChannel.length) break;

                        const left = lChannel[idx];
                        const right = rChannel[idx];

                        // Compute the sum and difference of left and right channels
                        const lrSum = (left + right) / 2;
                        const lrDiff = (left - right) / 2;

                        // Normalize values for visualization
                        const normSum = Math.sqrt(Math.abs(lrSum)) * Math.sign(lrSum) / 2 + 0.5;
                        const normDiff = lrDiff / 2 + 0.5;
                        // Map normalized values to Y, U, and V channels
                        tempY[j] = normSum;
                        if (j < 1920) {
                            tempU[j] = normDiff;
                            tempU[j + 1920] = normDiff;
                        } else {
                            tempV[j] = normDiff;
                            tempV[j - 1920] = normDiff;
                        }
                    }

                    // Convert YUV to RGB and update canvas image data
                    for (let j = 0; j < 3840; j++) {
                        const y = tempY[j];
                        const u = tempU[j];
                        const v = tempV[j];

                        // YUV to RGB conversion formula
                        let r = y + 1.402 * (v - 0.5);
                        let g = y - 0.344136 * (u - 0.5) - 0.714136 * (v - 0.5);
                        let b = y + 1.772 * (u - 0.5);

                        // Ensure the index is within bounds for image data
                        const pixelIdx = (i + j) * 4;
                        if (i + j > lChannel.length || pixelIdx >= data.length) break;

                        // Assign RGB values to image data
                        data[pixelIdx] = r * 255;
                        data[pixelIdx + 1] = g * 255;
                        data[pixelIdx + 2] = b * 255;
                        data[pixelIdx + 3] = 255; // Fully opaque
                    }
                }

                // Update canvas with processed image data
                ctx.putImageData(imageData, 0, 0);

                this.ptr = prevPos;
            }
        }


        const player = new Player(imageData);

        // Convert audio to image
        audioToImageBtn.addEventListener('click', () => {
            let file = audioFileInput.files[0];
            if (file) {
                let reader = new FileReader();
                reader.onload = (event) => {
                    const buffer = event.target.result;
                    // Decode the audio buffer and process the data
                    audioContext.decodeAudioData(buffer, (decodedBuffer) => {
                        player.record(decodedBuffer)
                    });

                };
                reader.readAsArrayBuffer(file);
            }
        });

        imageFileInput.addEventListener('change', e => {
            let imageFile = imageFileInput.files[0];
            if (imageFile) {
                let reader = new FileReader();
                reader.onload = (e) => {
                    let img = new Image();
                    img.onload = () => {
                        ctx.drawImage(img, 0, 0, canvas.width, canvas.height);
                        let imgData = ctx.getImageData(0, 0, canvas.width, canvas.height);
                        imageData.data.set(imgData.data)
                    };
                    img.src = e.target.result;
                };
                reader.readAsDataURL(imageFile);
            }
        })

        // Convert image to audio
        eraseBtn.addEventListener('click', () => {
            ctx.fillRect(0, 0, canvas.width, canvas.height);
            let imgData = ctx.getImageData(0, 0, canvas.width, canvas.height);
            imageData.data.set(imgData.data)
        });

        pauseBtn.addEventListener('click', e => {
            player.start()
            player.pause = player.isPlaying;
            if (!player.isPlaying) pauseBtn.textContent = '‚ñ∂';
            else pauseBtn.textContent = '‚è∏';
        })

        downloadBtn.addEventListener('click', e => {
            canvas.toBlob(blob => {
                const url = URL.createObjectURL(blob);
                let a = document.createElement("a");
                a.href = url;
                a.download = "tape.png";
                a.click();
            });
        })

        canvas.addEventListener('click', e=>{
            const p = e.offsetY/canvas.offsetHeight;
            player.currentTime = p * player.duration;
        })

    </script>
</body>

</html>